{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install sentencepiece","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-18T17:17:44.444572Z","iopub.execute_input":"2023-02-18T17:17:44.445053Z","iopub.status.idle":"2023-02-18T17:18:05.285017Z","shell.execute_reply.started":"2023-02-18T17:17:44.444966Z","shell.execute_reply":"2023-02-18T17:18:05.283827Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.11)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (0.1.97)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# Importing the libraries needed\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport seaborn as sns\nimport transformers\nimport json\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import RobertaModel, RobertaTokenizer\nimport logging\nlogging.basicConfig(level=logging.ERROR)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:26:29.766803Z","iopub.execute_input":"2023-02-18T17:26:29.767313Z","iopub.status.idle":"2023-02-18T17:26:33.252824Z","shell.execute_reply.started":"2023-02-18T17:26:29.767222Z","shell.execute_reply":"2023-02-18T17:26:33.251682Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForMaskedLM\n\nfrom transformers import AutoTokenizer, AutoModel\nimport re\n\ntokenizer = AutoTokenizer.from_pretrained(\"jhu-clsp/bernice\", model_max_length=128)\n#AutoTokenizer.from_pretrained(\"jhu-clsp/bernice\")","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:26:37.886436Z","iopub.execute_input":"2023-02-18T17:26:37.886823Z","iopub.status.idle":"2023-02-18T17:26:44.543729Z","shell.execute_reply.started":"2023-02-18T17:26:37.886786Z","shell.execute_reply":"2023-02-18T17:26:44.542680Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/489 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5972f93c4ed740c69ebcd9850f9078b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/4.44M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db80262937d04bda8d46170bcae11796"}},"metadata":{}}]},{"cell_type":"code","source":"# Setting up the device for GPU usage\n\nfrom torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:26:48.945856Z","iopub.execute_input":"2023-02-18T17:26:48.946752Z","iopub.status.idle":"2023-02-18T17:26:48.952274Z","shell.execute_reply.started":"2023-02-18T17:26:48.946705Z","shell.execute_reply":"2023-02-18T17:26:48.951345Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:26:52.426901Z","iopub.execute_input":"2023-02-18T17:26:52.427410Z","iopub.status.idle":"2023-02-18T17:26:52.433810Z","shell.execute_reply.started":"2023-02-18T17:26:52.427371Z","shell.execute_reply":"2023-02-18T17:26:52.432728Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load whole datasets\ndf_train = pd.read_csv(\"/kaggle/input/ipo-wholedataset/IPO_WholeDataset_ClassCreate.csv\", names = [\"tweet\", \"classes\"])","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:26:55.266619Z","iopub.execute_input":"2023-02-18T17:26:55.267108Z","iopub.status.idle":"2023-02-18T17:26:55.289100Z","shell.execute_reply.started":"2023-02-18T17:26:55.267067Z","shell.execute_reply":"2023-02-18T17:26:55.288154Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.iloc[1: , :]\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:26:58.026884Z","iopub.execute_input":"2023-02-18T17:26:58.027365Z","iopub.status.idle":"2023-02-18T17:26:58.049020Z","shell.execute_reply.started":"2023-02-18T17:26:58.027325Z","shell.execute_reply":"2023-02-18T17:26:58.048101Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                               tweet classes\n1  Millions of Indians investing in the country’s...     0.0\n2  టోకు ద్రవ్యోల్బణమే కీలకం  via తాజా వార్తలు  | ...     1.0\n3  મેરે રે કો એસે ધક ધક હો રહા હે....\\nfingers cr...     1.0\n4  The country's largest insurer will list itself...     1.0\n5  Can a full time employee ask for board of dire...     1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>classes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Millions of Indians investing in the country’s...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>టోకు ద్రవ్యోల్బణమే కీలకం  via తాజా వార్తలు  | ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>મેરે રે કો એસે ધક ધક હો રહા હે....\\nfingers cr...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The country's largest insurer will list itself...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Can a full time employee ask for board of dire...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:27:02.401465Z","iopub.execute_input":"2023-02-18T17:27:02.401888Z","iopub.status.idle":"2023-02-18T17:27:02.426826Z","shell.execute_reply.started":"2023-02-18T17:27:02.401854Z","shell.execute_reply":"2023-02-18T17:27:02.426001Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                    tweet classes\ncount                                                 960     960\nunique                                                944       3\ntop     Kaun kaun god se prey kar rahe ki unko LICIPO ...     1.0\nfreq                                                    3     657","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>classes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>960</td>\n      <td>960</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>944</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Kaun kaun god se prey kar rahe ki unko LICIPO ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>3</td>\n      <td>657</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Defining some key variables that will be used later on in the training\nMAX_LEN = 256\nTRAIN_BATCH_SIZE = 8\nVALID_BATCH_SIZE = 4\n#LEARNING_RATE = 1e-06\nLEARNING_RATE = 1e-08","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:27:45.546091Z","iopub.execute_input":"2023-02-18T17:27:45.546446Z","iopub.status.idle":"2023-02-18T17:27:45.551336Z","shell.execute_reply.started":"2023-02-18T17:27:45.546417Z","shell.execute_reply":"2023-02-18T17:27:45.550212Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class SentimentData(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.text = dataframe.tweet\n        #self.targets = self.data.class\n        # using loop\n        #y=list(df_train['class'])\n        y=list(dataframe.classes)\n        res = [eval(i) for i in y]\n        print(\"Modified list is: \", res)\n        yInt = [int(res) for res in res]\n        print(\"final->\",yInt)\n        self.targets = yInt\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        text = str(self.text[index])\n        text = \" \".join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n            #'targets': torch.tensor(self.targets[index], dtype=torch.str)\n        }","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:27:48.376569Z","iopub.execute_input":"2023-02-18T17:27:48.376922Z","iopub.status.idle":"2023-02-18T17:27:48.388458Z","shell.execute_reply.started":"2023-02-18T17:27:48.376891Z","shell.execute_reply":"2023-02-18T17:27:48.387494Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_size = 0.6\ntrain_data=df_train.sample(frac=train_size,random_state=200)\ntest_data=df_train.drop(train_data.index).reset_index(drop=True)\ntrain_data = train_data.reset_index(drop=True)\n\n\nprint(\"FULL Dataset: {}\".format(df_train.shape))\nprint(\"TRAIN Dataset: {}\".format(train_data.shape))\nprint(\"TEST Dataset: {}\".format(test_data.shape))\n\ntraining_set = SentimentData(train_data, tokenizer, MAX_LEN)\ntesting_set = SentimentData(test_data, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:27:52.346213Z","iopub.execute_input":"2023-02-18T17:27:52.346605Z","iopub.status.idle":"2023-02-18T17:27:52.365366Z","shell.execute_reply.started":"2023-02-18T17:27:52.346571Z","shell.execute_reply":"2023-02-18T17:27:52.364127Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"FULL Dataset: (960, 2)\nTRAIN Dataset: (576, 2)\nTEST Dataset: (384, 2)\nModified list is:  [1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0]\nfinal-> [1, 1, 1, 2, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 2, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 0, 1, 1, 1, 2, 2, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 0, 2, 1, 2, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 2, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1]\nModified list is:  [0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]\nfinal-> [0, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 2, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 0, 1, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntest_params = {'batch_size': VALID_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:28:03.046221Z","iopub.execute_input":"2023-02-18T17:28:03.046589Z","iopub.status.idle":"2023-02-18T17:28:03.051884Z","shell.execute_reply.started":"2023-02-18T17:28:03.046552Z","shell.execute_reply":"2023-02-18T17:28:03.050906Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#weights = [.762, .5, .923]\nweights = [.762, .316, .923]\n#weights = [.762, .684, .923]\nclass_weights=torch.tensor(weights,dtype=torch.float)\nloss_function = torch.nn.CrossEntropyLoss(weight = class_weights)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:28:06.446409Z","iopub.execute_input":"2023-02-18T17:28:06.446763Z","iopub.status.idle":"2023-02-18T17:28:06.453014Z","shell.execute_reply.started":"2023-02-18T17:28:06.446731Z","shell.execute_reply":"2023-02-18T17:28:06.451950Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class BerniceClass(torch.nn.Module):\n    def __init__(self):\n        super(BerniceClass, self).__init__()\n        self.l1 = AutoModelForMaskedLM.from_pretrained(\"jhu-clsp/bernice\")\n        #self.pre_classifier = torch.nn.Linear(768, 768)\n        #self.pre_classifier = torch.nn.Linear(768, 68)\n        self.pre_classifier = torch.nn.Linear(250000, 68)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.classifier = torch.nn.Linear(68, 3)\n        self.loss_fn = loss_function\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        hidden_state = output_1[0]\n        pooler = hidden_state[:, 0]\n        pooler = self.pre_classifier(pooler)\n        pooler = torch.nn.ReLU()(pooler)\n        pooler = self.dropout(pooler)\n        output = self.classifier(pooler)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:28:08.701352Z","iopub.execute_input":"2023-02-18T17:28:08.701721Z","iopub.status.idle":"2023-02-18T17:28:08.709748Z","shell.execute_reply.started":"2023-02-18T17:28:08.701689Z","shell.execute_reply":"2023-02-18T17:28:08.708640Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = BerniceClass()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:28:12.266249Z","iopub.execute_input":"2023-02-18T17:28:12.266608Z","iopub.status.idle":"2023-02-18T17:29:10.611745Z","shell.execute_reply.started":"2023-02-18T17:28:12.266577Z","shell.execute_reply":"2023-02-18T17:29:10.610766Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5611ffee0f7a4956b61d00dece7ada1b"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"BerniceClass(\n  (l1): XLMRobertaForMaskedLM(\n    (roberta): RobertaModel(\n      (embeddings): RobertaEmbeddings(\n        (word_embeddings): Embedding(250000, 768, padding_idx=1)\n        (position_embeddings): Embedding(130, 768, padding_idx=1)\n        (token_type_embeddings): Embedding(1, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): RobertaEncoder(\n        (layer): ModuleList(\n          (0): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (1): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (2): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (3): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (4): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (5): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (6): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (7): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (8): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (9): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (10): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (11): RobertaLayer(\n            (attention): RobertaAttention(\n              (self): RobertaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): RobertaSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): RobertaIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): RobertaOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (lm_head): RobertaLMHead(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (decoder): Linear(in_features=768, out_features=250000, bias=True)\n    )\n  )\n  (pre_classifier): Linear(in_features=250000, out_features=68, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=68, out_features=3, bias=True)\n  (loss_fn): CrossEntropyLoss()\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Creating optimizer\n#optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n#optimizer = torch.optim.RMSprop(params =  model.parameters(), lr=LEARNING_RATE)\noptimizer = torch.optim.SGD(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:29:18.346928Z","iopub.execute_input":"2023-02-18T17:29:18.347531Z","iopub.status.idle":"2023-02-18T17:29:18.355999Z","shell.execute_reply.started":"2023-02-18T17:29:18.347497Z","shell.execute_reply":"2023-02-18T17:29:18.355114Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"predicted11 = []\noriginal11=[]\ndef calcuate_accuracy(preds, targets):\n    predicted11.append(preds.tolist())\n    original11.append(targets.tolist())\n    n_correct = (preds==targets).sum().item()\n    return n_correct","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:29:20.956074Z","iopub.execute_input":"2023-02-18T17:29:20.956770Z","iopub.status.idle":"2023-02-18T17:29:20.961959Z","shell.execute_reply.started":"2023-02-18T17:29:20.956732Z","shell.execute_reply":"2023-02-18T17:29:20.961035Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def calcuate_accuracyTrain(preds, targets):\n    n_correct = (preds==targets).sum().item()\n    print(\"Inside accuracyTrain() method\")\n    return n_correct","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:29:24.166335Z","iopub.execute_input":"2023-02-18T17:29:24.166711Z","iopub.status.idle":"2023-02-18T17:29:24.172446Z","shell.execute_reply.started":"2023-02-18T17:29:24.166678Z","shell.execute_reply":"2023-02-18T17:29:24.171400Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def train(epoch):\n    tr_loss = 0\n    n_correct = 0\n    nb_tr_steps = 0\n    nb_tr_examples = 0\n    model.train()\n    for _,data in tqdm(enumerate(training_loader, 0)):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.long)\n\n        outputs = model(ids, mask, token_type_ids)\n        loss = loss_function(outputs, targets)\n        tr_loss += loss.item()\n        big_val, big_idx = torch.max(outputs.data, dim=1)\n        n_correct += calcuate_accuracyTrain(big_idx, targets)\n\n        nb_tr_steps += 1\n        nb_tr_examples+=targets.size(0)\n        \n        if _%5000==0:\n            loss_step = tr_loss/nb_tr_steps\n            accu_step = (n_correct*100)/nb_tr_examples \n            print(f\"Training Loss per 5000 steps: {loss_step}\")\n            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n\n        optimizer.zero_grad()\n        loss.backward()\n        # # When using GPU\n        optimizer.step()\n\n    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n    epoch_loss = tr_loss/nb_tr_steps\n    epoch_accu = (n_correct*100)/nb_tr_examples\n    print(f\"Training Loss Epoch: {epoch_loss}\")\n    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n\n    return ","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:29:26.697987Z","iopub.execute_input":"2023-02-18T17:29:26.698398Z","iopub.status.idle":"2023-02-18T17:29:26.763660Z","shell.execute_reply.started":"2023-02-18T17:29:26.698365Z","shell.execute_reply":"2023-02-18T17:29:26.762748Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 4\nfor epoch in range(EPOCHS):\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:29:31.546501Z","iopub.execute_input":"2023-02-18T17:29:31.546876Z","iopub.status.idle":"2023-02-18T17:32:00.867833Z","shell.execute_reply.started":"2023-02-18T17:29:31.546844Z","shell.execute_reply":"2023-02-18T17:32:00.866847Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n1it [00:01,  1.75s/it]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\nTraining Loss per 5000 steps: 1.3322943449020386\nTraining Accuracy per 5000 steps: 12.5\n","output_type":"stream"},{"name":"stderr","text":"2it [00:02,  1.02s/it]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"3it [00:02,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"4it [00:03,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"5it [00:03,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"6it [00:04,  1.71it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"7it [00:04,  1.78it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"8it [00:05,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"9it [00:05,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"10it [00:06,  1.89it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"11it [00:06,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"12it [00:07,  1.92it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"13it [00:07,  1.92it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"14it [00:08,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"15it [00:08,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"16it [00:09,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"17it [00:09,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"18it [00:10,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"19it [00:10,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"20it [00:11,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"21it [00:12,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"22it [00:12,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"23it [00:13,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"24it [00:13,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"25it [00:14,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"26it [00:14,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"27it [00:15,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"28it [00:15,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"29it [00:16,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"30it [00:16,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"31it [00:17,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"32it [00:17,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"33it [00:18,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"34it [00:18,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"35it [00:19,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"36it [00:19,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"37it [00:20,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"38it [00:20,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"39it [00:21,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"40it [00:21,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"41it [00:22,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"42it [00:22,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"43it [00:23,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"44it [00:23,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"45it [00:24,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"46it [00:24,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"47it [00:25,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"48it [00:25,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"49it [00:26,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"50it [00:26,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"51it [00:27,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"52it [00:27,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"53it [00:28,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"54it [00:29,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"55it [00:29,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"56it [00:30,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"57it [00:30,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"58it [00:31,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"59it [00:31,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"60it [00:32,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"61it [00:32,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"62it [00:33,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"63it [00:33,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"64it [00:34,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"65it [00:34,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"66it [00:35,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"67it [00:35,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"68it [00:36,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"69it [00:36,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"70it [00:37,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"71it [00:37,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"72it [00:38,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\nThe Total Accuracy for Epoch 0: 28.29861111111111\nTraining Loss Epoch: 1.2667658908499613\nTraining Accuracy Epoch: 28.29861111111111\n","output_type":"stream"},{"name":"stderr","text":"1it [00:00,  1.98it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\nTraining Loss per 5000 steps: 0.9932937026023865\nTraining Accuracy per 5000 steps: 50.0\n","output_type":"stream"},{"name":"stderr","text":"2it [00:01,  1.96it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"3it [00:01,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"4it [00:02,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"5it [00:02,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"6it [00:03,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"7it [00:03,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"8it [00:04,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"9it [00:04,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"10it [00:05,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"11it [00:05,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"12it [00:06,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"13it [00:06,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"14it [00:07,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"15it [00:07,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"16it [00:08,  1.92it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"17it [00:08,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"18it [00:09,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"19it [00:09,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"20it [00:10,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"21it [00:10,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"22it [00:11,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"23it [00:11,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"24it [00:12,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"25it [00:12,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"26it [00:13,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"27it [00:13,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"28it [00:14,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"29it [00:14,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"30it [00:15,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"31it [00:15,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"32it [00:16,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"33it [00:16,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"34it [00:17,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"35it [00:17,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"36it [00:18,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"37it [00:19,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"38it [00:19,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"39it [00:20,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"40it [00:20,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"41it [00:21,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"42it [00:21,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"43it [00:22,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"44it [00:22,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"45it [00:23,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"46it [00:23,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"47it [00:24,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"48it [00:24,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"49it [00:25,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"50it [00:25,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"51it [00:26,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"52it [00:26,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"53it [00:27,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"54it [00:27,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"55it [00:28,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"56it [00:28,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"57it [00:29,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"58it [00:29,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"59it [00:30,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"60it [00:30,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"61it [00:31,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"62it [00:31,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"63it [00:32,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"64it [00:32,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"65it [00:33,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"66it [00:33,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"67it [00:34,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"68it [00:34,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"69it [00:35,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"70it [00:35,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"71it [00:36,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"72it [00:37,  1.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\nThe Total Accuracy for Epoch 1: 32.291666666666664\nTraining Loss Epoch: 1.213469644387563\nTraining Accuracy Epoch: 32.291666666666664\n","output_type":"stream"},{"name":"stderr","text":"1it [00:00,  1.98it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\nTraining Loss per 5000 steps: 1.4361941814422607\nTraining Accuracy per 5000 steps: 25.0\n","output_type":"stream"},{"name":"stderr","text":"2it [00:01,  1.96it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"3it [00:01,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"4it [00:02,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"5it [00:02,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"6it [00:03,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"7it [00:03,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"8it [00:04,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"9it [00:04,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"10it [00:05,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"11it [00:05,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"12it [00:06,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"13it [00:06,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"14it [00:07,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"15it [00:07,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"16it [00:08,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"17it [00:08,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"18it [00:09,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"19it [00:09,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"20it [00:10,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"21it [00:10,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"22it [00:11,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"23it [00:11,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"24it [00:12,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"25it [00:12,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"26it [00:13,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"27it [00:13,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"28it [00:14,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"29it [00:14,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"30it [00:15,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"31it [00:15,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"32it [00:16,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"33it [00:16,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"34it [00:17,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"35it [00:17,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"36it [00:18,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"37it [00:19,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"38it [00:19,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"39it [00:20,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"40it [00:20,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"41it [00:21,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"42it [00:21,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"43it [00:22,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"44it [00:22,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"45it [00:23,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"46it [00:23,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"47it [00:24,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"48it [00:24,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"49it [00:25,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"50it [00:25,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"51it [00:26,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"52it [00:26,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"53it [00:27,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"54it [00:27,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"55it [00:28,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"56it [00:28,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"57it [00:29,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"58it [00:29,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"59it [00:30,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"60it [00:30,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"61it [00:31,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"62it [00:31,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"63it [00:32,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"64it [00:32,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"65it [00:33,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"66it [00:33,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"67it [00:34,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"68it [00:34,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"69it [00:35,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"70it [00:35,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"71it [00:36,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"72it [00:37,  1.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\nThe Total Accuracy for Epoch 2: 35.9375\nTraining Loss Epoch: 1.2474663820531633\nTraining Accuracy Epoch: 35.9375\n","output_type":"stream"},{"name":"stderr","text":"1it [00:00,  1.97it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\nTraining Loss per 5000 steps: 1.3701586723327637\nTraining Accuracy per 5000 steps: 25.0\n","output_type":"stream"},{"name":"stderr","text":"2it [00:01,  1.96it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"3it [00:01,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"4it [00:02,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"5it [00:02,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"6it [00:03,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"7it [00:03,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"8it [00:04,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"9it [00:04,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"10it [00:05,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"11it [00:05,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"12it [00:06,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"13it [00:06,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"14it [00:07,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"15it [00:07,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"16it [00:08,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"17it [00:08,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"18it [00:09,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"19it [00:09,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"20it [00:10,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"21it [00:10,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"22it [00:11,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"23it [00:11,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"24it [00:12,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"25it [00:12,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"26it [00:13,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"27it [00:13,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"28it [00:14,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"29it [00:14,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"30it [00:15,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"31it [00:15,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"32it [00:16,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"33it [00:16,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"34it [00:17,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"35it [00:17,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"36it [00:18,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"37it [00:19,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"38it [00:19,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"39it [00:20,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"40it [00:20,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"41it [00:21,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"42it [00:21,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"43it [00:22,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"44it [00:22,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"45it [00:23,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"46it [00:23,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"47it [00:24,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"48it [00:24,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"49it [00:25,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"50it [00:25,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"51it [00:26,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"52it [00:26,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"53it [00:27,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"54it [00:27,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"55it [00:28,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"56it [00:28,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"57it [00:29,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"58it [00:29,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"59it [00:30,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"60it [00:30,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"61it [00:31,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"62it [00:31,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"63it [00:32,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"64it [00:32,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"65it [00:33,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"66it [00:33,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"67it [00:34,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"68it [00:34,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"69it [00:35,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"70it [00:35,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"71it [00:36,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\n","output_type":"stream"},{"name":"stderr","text":"72it [00:37,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Inside accuracyTrain() method\nThe Total Accuracy for Epoch 3: 40.27777777777778\nTraining Loss Epoch: 1.20125738862488\nTraining Accuracy Epoch: 40.27777777777778\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def valid(model, testing_loader):\n    model.eval()\n    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n    with torch.no_grad():\n        for _, data in tqdm(enumerate(testing_loader, 0)):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n            targets = data['targets'].to(device, dtype = torch.long)\n            outputs = model(ids, mask, token_type_ids).squeeze()\n            loss = loss_function(outputs, targets)\n            tr_loss += loss.item()\n            big_val, big_idx = torch.max(outputs.data, dim=1)\n            n_correct += calcuate_accuracy(big_idx, targets)\n\n            nb_tr_steps += 1\n            nb_tr_examples+=targets.size(0)\n            \n            if _%5000==0:\n                loss_step = tr_loss/nb_tr_steps\n                accu_step = (n_correct*100)/nb_tr_examples\n                print(f\"Validation Loss per 100 steps: {loss_step}\")\n                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n    epoch_loss = tr_loss/nb_tr_steps\n    epoch_accu = (n_correct*100)/nb_tr_examples\n    print(f\"Validation Loss Epoch: {epoch_loss}\")\n    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n    \n    return epoch_accu","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:32:05.396327Z","iopub.execute_input":"2023-02-18T17:32:05.396691Z","iopub.status.idle":"2023-02-18T17:32:05.407578Z","shell.execute_reply.started":"2023-02-18T17:32:05.396661Z","shell.execute_reply":"2023-02-18T17:32:05.406431Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"acc = valid(model, testing_loader)\nprint(\"Accuracy on test data = %0.2f%%\" % acc)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:32:09.946309Z","iopub.execute_input":"2023-02-18T17:32:09.946665Z","iopub.status.idle":"2023-02-18T17:32:18.677082Z","shell.execute_reply.started":"2023-02-18T17:32:09.946635Z","shell.execute_reply":"2023-02-18T17:32:18.676030Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"3it [00:00, 10.62it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Loss per 100 steps: 0.7799178957939148\nValidation Accuracy per 100 steps: 75.0\n","output_type":"stream"},{"name":"stderr","text":"96it [00:08, 11.01it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Loss Epoch: 1.0470377132296562\nValidation Accuracy Epoch: 52.083333333333336\nAccuracy on test data = 52.08%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(predicted11))\nprint(predicted11)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:32:24.126504Z","iopub.execute_input":"2023-02-18T17:32:24.127058Z","iopub.status.idle":"2023-02-18T17:32:24.136525Z","shell.execute_reply.started":"2023-02-18T17:32:24.127011Z","shell.execute_reply":"2023-02-18T17:32:24.135611Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"96\n[[0, 1, 1, 1], [1, 1, 0, 1], [0, 1, 1, 1], [1, 1, 1, 0], [1, 1, 1, 0], [0, 1, 0, 1], [1, 1, 1, 1], [0, 1, 0, 1], [1, 1, 1, 0], [0, 0, 0, 2], [0, 1, 1, 1], [0, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 0, 1, 0], [1, 2, 0, 1], [0, 0, 0, 0], [0, 0, 2, 1], [1, 1, 0, 1], [1, 0, 0, 1], [2, 1, 0, 1], [0, 0, 1, 0], [1, 1, 0, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 2], [1, 1, 0, 1], [1, 0, 1, 1], [0, 0, 1, 0], [1, 0, 0, 0], [2, 1, 0, 0], [1, 0, 2, 1], [0, 0, 0, 1], [2, 0, 0, 0], [0, 1, 1, 0], [1, 1, 1, 0], [0, 0, 0, 1], [1, 1, 1, 1], [0, 1, 0, 1], [1, 2, 0, 0], [1, 1, 1, 0], [0, 0, 1, 0], [1, 1, 1, 1], [0, 0, 1, 1], [0, 1, 0, 1], [1, 0, 0, 1], [0, 0, 0, 0], [0, 1, 2, 1], [0, 1, 0, 1], [0, 0, 0, 1], [0, 0, 0, 0], [1, 0, 0, 1], [0, 1, 1, 0], [0, 2, 0, 1], [1, 2, 0, 0], [0, 0, 0, 0], [1, 1, 2, 0], [0, 0, 2, 1], [1, 1, 1, 1], [2, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 1], [2, 1, 0, 0], [1, 0, 1, 0], [1, 1, 1, 1], [0, 0, 1, 1], [1, 0, 1, 2], [0, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0], [0, 1, 1, 0], [2, 1, 0, 0], [0, 0, 2, 0], [0, 1, 0, 1], [0, 1, 0, 2], [0, 0, 1, 2], [0, 1, 2, 0], [0, 0, 2, 0], [2, 0, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1], [1, 1, 1, 0], [0, 0, 1, 1], [1, 0, 1, 0], [0, 0, 1, 1], [1, 0, 0, 2], [1, 0, 0, 1], [0, 0, 2, 2], [1, 0, 1, 1], [1, 1, 0, 1], [2, 0, 1, 1], [0, 0, 1, 1], [0, 0, 0, 0], [0, 0, 0, 2]]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(original11))\nprint(original11)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:32:28.490888Z","iopub.execute_input":"2023-02-18T17:32:28.491821Z","iopub.status.idle":"2023-02-18T17:32:28.497293Z","shell.execute_reply.started":"2023-02-18T17:32:28.491786Z","shell.execute_reply":"2023-02-18T17:32:28.495808Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"96\n[[1, 1, 1, 1], [1, 1, 1, 2], [1, 1, 1, 1], [1, 1, 1, 2], [1, 1, 1, 0], [0, 1, 0, 1], [2, 2, 1, 1], [1, 0, 1, 1], [1, 1, 0, 0], [0, 1, 2, 1], [0, 1, 1, 2], [1, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 1], [1, 1, 1, 2], [1, 1, 1, 1], [1, 0, 1, 0], [1, 1, 1, 2], [0, 1, 2, 1], [1, 0, 1, 2], [1, 1, 1, 1], [2, 2, 0, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 0], [1, 0, 1, 1], [0, 1, 1, 0], [2, 0, 1, 1], [0, 1, 0, 1], [1, 1, 0, 1], [0, 1, 1, 0], [0, 2, 0, 1], [2, 1, 0, 1], [0, 1, 1, 1], [0, 0, 1, 1], [1, 2, 0, 0], [0, 1, 1, 1], [1, 0, 1, 1], [1, 0, 1, 1], [0, 1, 1, 1], [1, 1, 1, 1], [1, 0, 1, 1], [0, 0, 1, 1], [0, 1, 0, 0], [1, 1, 1, 2], [1, 1, 1, 0], [1, 1, 1, 1], [0, 2, 0, 1], [1, 0, 1, 0], [0, 0, 0, 1], [1, 1, 1, 1], [0, 0, 1, 1], [1, 1, 1, 0], [2, 0, 2, 1], [0, 1, 1, 0], [1, 1, 1, 1], [1, 2, 1, 1], [1, 1, 1, 1], [1, 0, 1, 1], [1, 0, 1, 1], [0, 1, 1, 1], [1, 1, 1, 1], [1, 0, 1, 2], [0, 0, 1, 1], [0, 0, 0, 1], [1, 1, 0, 1], [1, 1, 1, 1], [2, 1, 0, 1], [0, 1, 1, 1], [0, 1, 1, 1], [1, 1, 1, 1], [2, 1, 1, 1], [2, 1, 1, 1], [1, 1, 1, 1], [1, 0, 1, 1], [1, 0, 1, 1], [1, 0, 1, 1], [1, 1, 0, 0], [1, 0, 1, 1], [1, 0, 2, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 0, 1, 2], [1, 0, 1, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 2]]\n","output_type":"stream"}]},{"cell_type":"code","source":"final_prediction = []\nfor sublist in predicted11:\n    for item in sublist:\n        final_prediction.append(item)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:32:31.846293Z","iopub.execute_input":"2023-02-18T17:32:31.846655Z","iopub.status.idle":"2023-02-18T17:32:31.853044Z","shell.execute_reply.started":"2023-02-18T17:32:31.846623Z","shell.execute_reply":"2023-02-18T17:32:31.852059Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"final_original = []\nfor sublist in original11:\n    for item in sublist:\n        final_original.append(item)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:32:34.866430Z","iopub.execute_input":"2023-02-18T17:32:34.866782Z","iopub.status.idle":"2023-02-18T17:32:34.871982Z","shell.execute_reply.started":"2023-02-18T17:32:34.866753Z","shell.execute_reply":"2023-02-18T17:32:34.871067Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(len(final_prediction))\nprint(final_prediction)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:32:38.805963Z","iopub.execute_input":"2023-02-18T17:32:38.806352Z","iopub.status.idle":"2023-02-18T17:32:38.812237Z","shell.execute_reply.started":"2023-02-18T17:32:38.806324Z","shell.execute_reply":"2023-02-18T17:32:38.811029Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"384\n[0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 2, 1, 1, 1, 1, 1, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 2, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 2, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 2, 0, 2, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 2, 1, 0, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(final_original))\nprint(final_original)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:32:42.016078Z","iopub.execute_input":"2023-02-18T17:32:42.016749Z","iopub.status.idle":"2023-02-18T17:32:42.022276Z","shell.execute_reply.started":"2023-02-18T17:32:42.016712Z","shell.execute_reply":"2023-02-18T17:32:42.021071Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"384\n[1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 0, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 2, 1, 0, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 0, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 2, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 2, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 2, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 2, 0, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"import sklearn\nmat1 = sklearn.metrics.confusion_matrix(final_original,final_prediction)\nmat1","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:33:01.296794Z","iopub.execute_input":"2023-02-18T17:33:01.297185Z","iopub.status.idle":"2023-02-18T17:33:01.305059Z","shell.execute_reply.started":"2023-02-18T17:33:01.297154Z","shell.execute_reply":"2023-02-18T17:33:01.304141Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"array([[ 61,  25,   4],\n       [114, 133,  19],\n       [ 12,  10,   6]])"},"metadata":{}}]},{"cell_type":"code","source":"sklearn.metrics.accuracy_score(final_original,final_prediction)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:33:05.245962Z","iopub.execute_input":"2023-02-18T17:33:05.246340Z","iopub.status.idle":"2023-02-18T17:33:05.253357Z","shell.execute_reply.started":"2023-02-18T17:33:05.246308Z","shell.execute_reply":"2023-02-18T17:33:05.252429Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"0.5208333333333334"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\ndf_cm = pd.DataFrame(mat1, range(3), range(3))\n\nsns.heatmap(df_cm, annot=True) \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:33:25.752690Z","iopub.execute_input":"2023-02-18T17:33:25.753276Z","iopub.status.idle":"2023-02-18T17:33:26.073881Z","shell.execute_reply.started":"2023-02-18T17:33:25.753234Z","shell.execute_reply":"2023-02-18T17:33:26.073033Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:33:31.656836Z","iopub.execute_input":"2023-02-18T17:33:31.657874Z","iopub.status.idle":"2023-02-18T17:33:31.663376Z","shell.execute_reply.started":"2023-02-18T17:33:31.657836Z","shell.execute_reply":"2023-02-18T17:33:31.662049Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"precision,recall,fscore,support = precision_recall_fscore_support(final_original,final_prediction,labels=[0,1,2])","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:33:34.615868Z","iopub.execute_input":"2023-02-18T17:33:34.616565Z","iopub.status.idle":"2023-02-18T17:33:34.624379Z","shell.execute_reply.started":"2023-02-18T17:33:34.616521Z","shell.execute_reply":"2023-02-18T17:33:34.623162Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"precision","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:33:37.846616Z","iopub.execute_input":"2023-02-18T17:33:37.846963Z","iopub.status.idle":"2023-02-18T17:33:37.854168Z","shell.execute_reply.started":"2023-02-18T17:33:37.846933Z","shell.execute_reply":"2023-02-18T17:33:37.853034Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"array([0.32620321, 0.79166667, 0.20689655])"},"metadata":{}}]},{"cell_type":"code","source":"recall","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:33:41.766187Z","iopub.execute_input":"2023-02-18T17:33:41.766548Z","iopub.status.idle":"2023-02-18T17:33:41.772997Z","shell.execute_reply.started":"2023-02-18T17:33:41.766517Z","shell.execute_reply":"2023-02-18T17:33:41.772007Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"array([0.67777778, 0.5       , 0.21428571])"},"metadata":{}}]},{"cell_type":"code","source":"fscore","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:33:48.966652Z","iopub.execute_input":"2023-02-18T17:33:48.967034Z","iopub.status.idle":"2023-02-18T17:33:48.973871Z","shell.execute_reply.started":"2023-02-18T17:33:48.966994Z","shell.execute_reply":"2023-02-18T17:33:48.972917Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"array([0.44043321, 0.61290323, 0.21052632])"},"metadata":{}}]},{"cell_type":"code","source":"support","metadata":{"execution":{"iopub.status.busy":"2023-02-18T17:33:51.986400Z","iopub.execute_input":"2023-02-18T17:33:51.986748Z","iopub.status.idle":"2023-02-18T17:33:51.993850Z","shell.execute_reply.started":"2023-02-18T17:33:51.986718Z","shell.execute_reply":"2023-02-18T17:33:51.992944Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"array([ 90, 266,  28])"},"metadata":{}}]}]}